{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4eb3f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID  Year_Birth   Education Marital_Status      Income   Kidhome  \\\n",
      "0   1826        1970  Graduation       Divorced  $84,835.00         0   \n",
      "1      1        1961  Graduation         Single  $57,091.00         0   \n",
      "2  10476        1958  Graduation        Married  $67,267.00         0   \n",
      "3   1386        1967  Graduation       Together  $32,474.00         1   \n",
      "4   5371        1989  Graduation         Single  $21,474.00         1   \n",
      "\n",
      "   Teenhome Dt_Customer Country  \n",
      "0         0     6/16/14      SP  \n",
      "1         0     6/15/14      CA  \n",
      "2         1     5/13/14      US  \n",
      "3         1     5/11/14     AUS  \n",
      "4         0      4/8/14      SP  \n",
      "   Recency  MntWines  MntFruits  MntMeatProducts  MntFishProducts  \\\n",
      "0        0       189        104              379              111   \n",
      "1        0       464          5               64                7   \n",
      "2        0       134         11               59               15   \n",
      "3        0        10          0                1                0   \n",
      "4        0         6         16               24               11   \n",
      "\n",
      "   MntSweetProducts  MntGoldProds  NumDealsPurchases  NumWebPurchases  \\\n",
      "0               189           218                  1                4   \n",
      "1                 0            37                  1                7   \n",
      "2                 2            30                  1                3   \n",
      "3                 0             0                  1                1   \n",
      "4                 0            34                  2                3   \n",
      "\n",
      "   NumCatalogPurchases  NumStorePurchases  NumWebVisitsMonth     ID  \n",
      "0                    4                  6                  1   1826  \n",
      "1                    3                  7                  5      1  \n",
      "2                    2                  5                  2  10476  \n",
      "3                    0                  2                  7   1386  \n",
      "4                    1                  2                  7   5371  \n",
      "   AcceptedCmp1  AcceptedCmp2  AcceptedCmp3  AcceptedCmp4  AcceptedCmp5  \\\n",
      "0             0             0             0             0             0   \n",
      "1             0             1             0             0             0   \n",
      "2             0             0             0             0             0   \n",
      "3             0             0             0             0             0   \n",
      "4             0             0             1             0             0   \n",
      "\n",
      "   Response  Complain     ID  \n",
      "0         1         0   1826  \n",
      "1         1         0      1  \n",
      "2         0         0  10476  \n",
      "3         0         0   1386  \n",
      "4         1         0   5371  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "demographic_df  = pd.read_csv(\"/Users/akhilnair/Downloads/demographics.txt\", delimiter='\\t')\n",
    "print(demographic_df.head())\n",
    "\n",
    "with open(\"/Users/akhilnair/Downloads/behaviour.json\") as behaviour_file:\n",
    "    behaviour_data = json.load(behaviour_file)\n",
    "with open(\"/Users/akhilnair/Downloads/campaign.json\") as campaign_file:\n",
    "    campaign_data = json.load(campaign_file)\n",
    "\n",
    "# Converting the JSON data to DataFrames\n",
    "behaviour_list = [list(item.values())[0] for item in behaviour_data]\n",
    "behaviour_ids = [list(item.keys())[0].replace('ID_', '') for item in behaviour_data]\n",
    "behaviour_df = pd.DataFrame(behaviour_list)\n",
    "behaviour_df['ID'] = behaviour_ids\n",
    "print(behaviour_df.head())\n",
    "\n",
    "campaign_list = [list(item.values())[0] for item in campaign_data]\n",
    "campaign_ids = [list(item.keys())[0].replace('ID_', '') for item in campaign_data]\n",
    "campaign_df = pd.DataFrame(campaign_list)\n",
    "campaign_df['ID'] = campaign_ids\n",
    "print(campaign_df.head())\n",
    "\n",
    "# Converting ID columns to string type for consistent joining\n",
    "demographic_df['ID'] = demographic_df['ID'].astype(str)\n",
    "behaviour_df['ID'] = behaviour_df['ID'].astype(str)\n",
    "campaign_df['ID'] = campaign_df['ID'].astype(str)\n",
    "\n",
    "# Merging the datasets on ID\n",
    "consolidated_df = demographic_df.merge(behaviour_df, on='ID').merge(campaign_df, on='ID')\n",
    "\n",
    "# Removing extra spaces in column names\n",
    "consolidated_df.columns = consolidated_df.columns.str.strip()\n",
    "consolidated_df\n",
    "\n",
    "# Cleaning and convert the Income column\n",
    "consolidated_df['Income'] = consolidated_df['Income'].replace('[\\$,]', '', regex=True).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b360252d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Year_Birth</th>\n",
       "      <th>Education</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Income</th>\n",
       "      <th>Kidhome</th>\n",
       "      <th>Teenhome</th>\n",
       "      <th>Dt_Customer</th>\n",
       "      <th>Country</th>\n",
       "      <th>Recency</th>\n",
       "      <th>...</th>\n",
       "      <th>NumCatalogPurchases</th>\n",
       "      <th>NumStorePurchases</th>\n",
       "      <th>NumWebVisitsMonth</th>\n",
       "      <th>AcceptedCmp1</th>\n",
       "      <th>AcceptedCmp2</th>\n",
       "      <th>AcceptedCmp3</th>\n",
       "      <th>AcceptedCmp4</th>\n",
       "      <th>AcceptedCmp5</th>\n",
       "      <th>Response</th>\n",
       "      <th>Complain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1826</td>\n",
       "      <td>1970</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>84835.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6/16/14</td>\n",
       "      <td>SP</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1961</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Single</td>\n",
       "      <td>57091.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6/15/14</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10476</td>\n",
       "      <td>1958</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Married</td>\n",
       "      <td>67267.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5/13/14</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1386</td>\n",
       "      <td>1967</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Together</td>\n",
       "      <td>32474.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5/11/14</td>\n",
       "      <td>AUS</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5371</td>\n",
       "      <td>1989</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Single</td>\n",
       "      <td>21474.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4/8/14</td>\n",
       "      <td>SP</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2235</th>\n",
       "      <td>10142</td>\n",
       "      <td>1976</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>66476.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3/7/13</td>\n",
       "      <td>US</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2236</th>\n",
       "      <td>5263</td>\n",
       "      <td>1977</td>\n",
       "      <td>2n Cycle</td>\n",
       "      <td>Married</td>\n",
       "      <td>31056.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1/22/13</td>\n",
       "      <td>SP</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2237</th>\n",
       "      <td>22</td>\n",
       "      <td>1976</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>46310.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12/3/12</td>\n",
       "      <td>SP</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2238</th>\n",
       "      <td>528</td>\n",
       "      <td>1978</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Married</td>\n",
       "      <td>65819.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11/29/12</td>\n",
       "      <td>IND</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2239</th>\n",
       "      <td>4070</td>\n",
       "      <td>1969</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Married</td>\n",
       "      <td>94871.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9/1/12</td>\n",
       "      <td>CA</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2240 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  Year_Birth   Education Marital_Status   Income  Kidhome  \\\n",
       "0      1826        1970  Graduation       Divorced  84835.0        0   \n",
       "1         1        1961  Graduation         Single  57091.0        0   \n",
       "2     10476        1958  Graduation        Married  67267.0        0   \n",
       "3      1386        1967  Graduation       Together  32474.0        1   \n",
       "4      5371        1989  Graduation         Single  21474.0        1   \n",
       "...     ...         ...         ...            ...      ...      ...   \n",
       "2235  10142        1976         PhD       Divorced  66476.0        0   \n",
       "2236   5263        1977    2n Cycle        Married  31056.0        1   \n",
       "2237     22        1976  Graduation       Divorced  46310.0        1   \n",
       "2238    528        1978  Graduation        Married  65819.0        0   \n",
       "2239   4070        1969         PhD        Married  94871.0        0   \n",
       "\n",
       "      Teenhome Dt_Customer Country  Recency  ...  NumCatalogPurchases  \\\n",
       "0            0     6/16/14      SP        0  ...                    4   \n",
       "1            0     6/15/14      CA        0  ...                    3   \n",
       "2            1     5/13/14      US        0  ...                    2   \n",
       "3            1     5/11/14     AUS        0  ...                    0   \n",
       "4            0      4/8/14      SP        0  ...                    1   \n",
       "...        ...         ...     ...      ...  ...                  ...   \n",
       "2235         1      3/7/13      US       99  ...                    2   \n",
       "2236         0     1/22/13      SP       99  ...                    0   \n",
       "2237         0     12/3/12      SP       99  ...                    1   \n",
       "2238         0    11/29/12     IND       99  ...                    4   \n",
       "2239         2      9/1/12      CA       99  ...                    5   \n",
       "\n",
       "      NumStorePurchases  NumWebVisitsMonth  AcceptedCmp1  AcceptedCmp2  \\\n",
       "0                     6                  1             0             0   \n",
       "1                     7                  5             0             1   \n",
       "2                     5                  2             0             0   \n",
       "3                     2                  7             0             0   \n",
       "4                     2                  7             0             0   \n",
       "...                 ...                ...           ...           ...   \n",
       "2235                 11                  4             0             0   \n",
       "2236                  3                  8             0             0   \n",
       "2237                  5                  8             0             0   \n",
       "2238                 10                  3             0             0   \n",
       "2239                  4                  7             0             0   \n",
       "\n",
       "      AcceptedCmp3  AcceptedCmp4  AcceptedCmp5  Response  Complain  \n",
       "0                0             0             0         1         0  \n",
       "1                0             0             0         1         0  \n",
       "2                0             0             0         0         0  \n",
       "3                0             0             0         0         0  \n",
       "4                1             0             0         1         0  \n",
       "...            ...           ...           ...       ...       ...  \n",
       "2235             0             0             0         0         0  \n",
       "2236             0             0             0         0         0  \n",
       "2237             0             0             0         0         0  \n",
       "2238             0             0             0         0         0  \n",
       "2239             0             1             1         1         0  \n",
       "\n",
       "[2240 rows x 28 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing extra spaces in column names\n",
    "consolidated_df.columns = consolidated_df.columns.str.strip()\n",
    "consolidated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72a61f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning and convert the Income column\n",
    "consolidated_df['Income'] = consolidated_df['Income'].replace('[\\$,]', '', regex=True).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "322ec205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining feature columns and target variable\n",
    "features = ['Year_Birth', 'Income', 'Kidhome', 'Teenhome', 'Recency', \n",
    "            'MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', \n",
    "            'MntSweetProducts', 'MntGoldProds', 'NumDealsPurchases', \n",
    "            'NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases', \n",
    "            'NumWebVisitsMonth']\n",
    "target = 'Response'\n",
    "\n",
    "# Converting categorical columns to dummy variables\n",
    "consolidated_df = pd.get_dummies(consolidated_df, columns=['Education', 'Marital_Status', 'Country'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77b345cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values using SimpleImputer\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X = consolidated_df[features]\n",
    "X = imputer.fit_transform(X)  \n",
    "y = consolidated_df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe250d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Training Logistic Regression model\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred_log_reg = log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eef3798c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92       567\n",
      "           1       0.55      0.20      0.29       105\n",
      "\n",
      "    accuracy                           0.85       672\n",
      "   macro avg       0.71      0.59      0.60       672\n",
      "weighted avg       0.82      0.85      0.82       672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluating Logistic Regression model\n",
    "print(\"Logistic Regression Model\")\n",
    "log_reg_report = classification_report(y_test, y_pred_log_reg)\n",
    "print(log_reg_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c93eb328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[550  17]\n",
      " [ 84  21]]\n"
     ]
    }
   ],
   "source": [
    "log_reg_confusion_matrix = confusion_matrix(y_test, y_pred_log_reg)\n",
    "print(log_reg_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5cd1bf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Random Forest model\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c1558c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92       567\n",
      "           1       0.63      0.30      0.40       105\n",
      "\n",
      "    accuracy                           0.86       672\n",
      "   macro avg       0.76      0.63      0.66       672\n",
      "weighted avg       0.84      0.86      0.84       672\n",
      "\n",
      "[[549  18]\n",
      " [ 74  31]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluating Random Forest model\n",
    "print(\"Random Forest Model\")\n",
    "rf_report = classification_report(y_test, y_pred_rf)\n",
    "print(rf_report)\n",
    "rf_confusion_matrix = confusion_matrix(y_test, y_pred_rf)\n",
    "print(rf_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcaf686",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
